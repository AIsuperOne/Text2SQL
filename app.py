import streamlit as st
import pandas as pd
import numpy as np
from streamlit_echarts import st_pyecharts
from modules.rag_engine import RAGEngine
from modules.training_manager import BatchTrainer
from utils.plot_executor import PlotExecutor

# ----------------- æ–°çš„ã€æ›´ç®€å•çš„å›¾è¡¨æ„å»ºå™¨ -----------------
def build_simple_chart(df: pd.DataFrame, title: str):
    """
    æ ¹æ®ç»™å®šçš„æ•°æ®æ¡†ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å›¾è¡¨ç±»å‹å¹¶æ„å»ºå›¾è¡¨ã€‚
    """
    from pyecharts import options as opts
    from pyecharts.charts import Bar, Line

    if df.empty:
        return None

    df_copy = df.copy()
    cols = df_copy.columns.tolist()
    
    dim_col, time_col, metric_cols = None, None, []

    # ä¼˜å…ˆå¯»æ‰¾æ—¶é—´åˆ—
    for col in cols:
        if 'æ—¶é—´' in col or 'æ—¥æœŸ' in col:
            try:
                df_copy[col] = pd.to_datetime(df_copy[col])
                time_col = col
                break
            except (ValueError, TypeError):
                pass

    if time_col:
        dim_col = time_col
        metric_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df_copy[c])]
    else:
        for col in cols:
            if not pd.api.types.is_numeric_dtype(df_copy[col]):
                dim_col = col
                break
        if dim_col:
            metric_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df_copy[c]) and c != dim_col]
        else:
            dim_col = cols[0]
            metric_cols = cols[1:]

    if not dim_col or not metric_cols:
        return None

    global_opts = {
        "title_opts": opts.TitleOpts(title=title, pos_left="center"),
        "toolbox_opts": opts.ToolboxOpts(is_show=True, feature=opts.ToolBoxFeatureOpts(save_as_image=opts.ToolBoxFeatureSaveAsImageOpts(pixel_ratio=2))),
        "tooltip_opts": opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
        "datazoom_opts": [opts.DataZoomOpts(type_="slider"), opts.DataZoomOpts(type_="inside")]
    }

    if time_col:
        chart = Line(init_opts=opts.InitOpts(width="100%", height="500px"))
        df_copy = df_copy.sort_values(by=time_col)
        chart.add_xaxis(df_copy[time_col].dt.strftime('%Y-%m-%d %H:%M').tolist())
        
        yaxis_count = 0
        for y_col in metric_cols:
            if yaxis_count > 0: chart.extend_axis(yaxis=opts.AxisOpts(name=y_col, position="right", offset=yaxis_count * 60))
            chart.add_yaxis(y_col, df_copy[y_col].round(4).tolist(), yaxis_index=yaxis_count)
            yaxis_count += 1
        chart.set_global_opts(**global_opts, legend_opts=opts.LegendOpts(pos_left='center'))
    else:
        chart = Bar(init_opts=opts.InitOpts(width="100%", height="500px"))
        chart.add_xaxis(df_copy[dim_col].tolist())
        for y_col in metric_cols:
            chart.add_yaxis(y_col, df_copy[y_col].round(4).tolist())
        chart.set_global_opts(xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=30)), **global_opts)

    return chart


# ----------------- åº”ç”¨ä¸»é€»è¾‘ -----------------
st.set_page_config(page_title="NL2SQL RAG Demo", layout="wide")

# åˆå§‹åŒ–
if "rag_engine" not in st.session_state:
    st.session_state.rag_engine = RAGEngine()
if "trainer" not in st.session_state:
    st.session_state.trainer = BatchTrainer()

rag_engine = st.session_state.rag_engine
trainer = st.session_state.trainer

# åˆå§‹åŒ–æ‰€æœ‰æŸ¥è¯¢ç›¸å…³çš„session state
for key in ['generated_sql', 'current_question', 'refined_question', 'query_result', 'query_error', 'analysis_report']:
    if key not in st.session_state:
        st.session_state[key] = "" if key in ['generated_sql', 'current_question', 'refined_question'] else None


# åˆ›å»ºæ ‡ç­¾é¡µ
tabs = st.tabs(["ğŸ§‘â€ğŸ’» è‡ªç„¶è¯­è¨€æŸ¥è¯¢", "âš™ï¸ æ‰¹é‡/å¢é‡è®­ç»ƒ"])

# 1. æŸ¥è¯¢ç•Œé¢
with tabs[0]:
    st.header("TEXT2SQL")
    
    debug_mode = st.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=False)
    
    # --- ä¸‰æ­¥å¼å¸ƒå±€ ---
    col1, col2, col3 = st.columns(3)

    # Step 1: è¾“å…¥é—®é¢˜
    with col1:
        st.markdown("### Step 1: è¾“å…¥é—®é¢˜")
        question = st.text_area(
            "è¯·è¾“å…¥æ‚¨çš„ä¸šåŠ¡é—®é¢˜",
            height=150,
            placeholder="å¦‚ï¼šæŸ¥è¯¢æ¹–åŒ—çœçš„åŸºç«™æ•°é‡å’Œå°åŒºæ•°é‡",
            key="question_input"
        )
        
        if st.button("AIè¯†åˆ«æ„å›¾", type="primary", use_container_width=True):
            if question.strip():
                with st.spinner("AIæ­£åœ¨è¯†åˆ«æ‚¨çš„æŸ¥è¯¢æ„å›¾..."):
                    try:
                        # å‡†å¤‡ä¸€ä¸ªå¯ç”¨æŒ‡æ ‡çš„ç®€å•åˆ—è¡¨ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä»æ•°æ®åº“æˆ–é…ç½®ä¸­è·å–ï¼‰
                        available_metrics = [
                            "æ•°æ®ä¸šåŠ¡æµé‡", "æ— çº¿æ¥é€šç‡", "æ— çº¿æ‰çº¿ç‡", 
                            "ä¸Šè¡Œæ•°æ®ä¸šåŠ¡æµé‡", "ä¸‹è¡Œæ•°æ®ä¸šåŠ¡æµé‡", "ç³»ç»Ÿå†…åˆ‡æ¢æˆåŠŸç‡"
                        ]
                        
                        # è°ƒç”¨LLMè¿›è¡Œé—®é¢˜è§£æ„
                        refined = rag_engine.llm.refine_question(question.strip(), available_metrics)
                        st.session_state.refined_question = refined
                        st.session_state.current_question = question.strip() # ä¿å­˜åŸå§‹é—®é¢˜
                        
                        if debug_mode:
                            with st.expander("æŸ¥çœ‹æ¶¦è‰²è¿‡ç¨‹", expanded=True):
                                st.write("**åŸå§‹é—®é¢˜ï¼š**", st.session_state.current_question)
                                st.write("**ç»“æ„åŒ–åï¼š**")
                                st.text(refined)

                    except Exception as e:
                        st.error(f"é—®é¢˜è¯†åˆ«å¤±è´¥ï¼š{str(e)}")
                        # å¤±è´¥æ—¶ä½¿ç”¨åŸé—®é¢˜ä½œä¸ºæ„å›¾
                        st.session_state.refined_question = f"**æ ¸å¿ƒæ„å›¾**: {question.strip()}"
            else:
                st.warning("è¯·å…ˆè¾“å…¥é—®é¢˜")

    # Step 2: ç¡®è®¤æ„å›¾å¹¶ç”Ÿæˆ
    with col2:
        st.markdown("### Step 2: ç¡®è®¤æ„å›¾å¹¶ç”Ÿæˆ")
        
        # ä½¿ç”¨ st.text_area æ¥æ˜¾ç¤ºå’Œç¼–è¾‘æ¶¦è‰²åçš„é—®é¢˜ï¼Œä¸Step 1æ ¼å¼å¯¹é½
        refined_question_editable = st.text_area(
            "AIè¯†åˆ«å¹¶ç»“æ„åŒ–çš„æ„å›¾ï¼ˆå¯ç¼–è¾‘ï¼‰",
            value=st.session_state.refined_question,
            height=150,
            key="refined_question_editor",
            # å¦‚æœæ²¡æœ‰æ¶¦è‰²åçš„é—®é¢˜ï¼Œåˆ™ç¦ç”¨æ–‡æœ¬æ¡†
            disabled=not st.session_state.refined_question
        )
        
        # â€œç”ŸæˆSQLâ€æŒ‰é’®ï¼Œå…¶å¯ç”¨æ€§å–å†³äºæ–‡æœ¬æ¡†ä¸­æ˜¯å¦æœ‰å†…å®¹
        if st.button("ç”ŸæˆSQL", type="primary", use_container_width=True, disabled=not refined_question_editable.strip()):
            with st.spinner("æ­£åœ¨ç”ŸæˆSQL..."):
                try:
                    # ä½¿ç”¨æœ€ç»ˆç¼–è¾‘åçš„é—®é¢˜æ¥ç”ŸæˆSQL
                    final_question_for_sql = refined_question_editable.strip()
                    # æ›´æ–°session stateä¸­çš„æ¶¦è‰²é—®é¢˜ï¼Œä»¥å¤‡åç»­ä½¿ç”¨
                    st.session_state.refined_question = final_question_for_sql
                    
                    result = rag_engine.generate_sql_only(final_question_for_sql)
                    st.session_state.generated_sql = result["sql"]
                    
                    # æ¸…ç†åç»­çŠ¶æ€
                    st.session_state.query_result = None
                    st.session_state.query_error = None
                    st.session_state.analysis_report = None
                    st.rerun()
                except Exception as e:
                    st.error(f"SQLç”Ÿæˆå¤±è´¥ï¼š{str(e)}")



    # Step 3: ç¼–è¾‘å¹¶æ‰§è¡Œ
    with col3:
        st.markdown("### Step 3: ç¼–è¾‘å¹¶æ‰§è¡ŒSQL")
        
        edited_sql = st.text_area(
            "AI2SQLç¼–è¾‘å™¨",
            value=st.session_state.generated_sql,
            height=150,
            key="sql_editor",
            disabled=not st.session_state.generated_sql
        )
        
        btn_col1, btn_col2 = st.columns(2)
        with btn_col1:
            if st.button("â–¶ï¸ SQLæ‰§è¡Œ", type="primary", use_container_width=True, disabled=not edited_sql.strip()):
                with st.spinner("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢..."):
                    try:
                        df = rag_engine.db.execute_query(edited_sql)
                        st.session_state.query_result = df
                        st.session_state.query_error = None
                        st.session_state.analysis_report = None
                    except Exception as e:
                        st.session_state.query_result = None
                        st.session_state.query_error = str(e)
        
        with btn_col2:
            if st.button("ğŸ’¾ ä¿å­˜åˆ°è®­ç»ƒ", type="secondary", use_container_width=True, disabled=not edited_sql.strip()):
                if st.session_state.current_question and edited_sql:
                    # ... ä¿å­˜é€»è¾‘ ...
                    st.success("å·²ä¿å­˜ï¼")
                else:
                    st.warning("ç¼ºå°‘åŸå§‹é—®é¢˜æˆ–SQL")

    # --- åç»­æ˜¾ç¤ºåŒºåŸŸ ---
    if st.session_state.query_error:
        st.error(f"âŒ SQLæ‰§è¡Œé”™è¯¯: {st.session_state.query_error}")
    
    if st.session_state.query_result is not None:
        result_df = st.session_state.query_result
        if not result_df.empty:
            st.divider()
            st.subheader("æŸ¥è¯¢ç»“æœ")
            st.dataframe(result_df, use_container_width=True)
            
            # AI æ™ºèƒ½æ•°æ®å¯è§†åŒ–
            st.divider()
            st.subheader("ğŸ¤– AI æ™ºèƒ½æ•°æ®å¯è§†åŒ–")

            if st.button("ğŸ”¬ ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š", type="primary"):
                with st.spinner("AIæ­£åœ¨æ‰§è¡Œæ·±åº¦åˆ†æ..."):
                    try:
                        # --- æ•°æ®é¢„å¤„ç†å’Œæ‘˜è¦ç”Ÿæˆ ---
                        dimension_cols = ['å¼€å§‹æ—¶é—´', 'çœä»½', 'åœ°å¸‚', 'åŒºå¿', 'ä¹¡é•‡', 'æ‘åŒº', 'station_name', 'cell_name', 'frequency_band']
                        existing_dims = [col for col in dimension_cols if col in result_df.columns]
                        metric_cols = [col for col in result_df.select_dtypes(include=np.number).columns if col not in existing_dims]
                        
                        pre_analysis_summary = ""
                        overall_avg_series = None
                        if existing_dims and metric_cols:
                            grouped_analysis_df = result_df.groupby(existing_dims)[metric_cols].mean().round(4)
                            overall_avg_series = result_df[metric_cols].mean().round(4)
                            std_dev_series = result_df[metric_cols].std().round(4)
                            coeff_var_series = (std_dev_series / overall_avg_series).abs().round(4)
                            
                            st.session_state.overall_avg_series = overall_avg_series # ä¿å­˜å…¨å±€å¹³å‡å€¼ä»¥ä¾›åç»­ä½¿ç”¨

                            pre_analysis_summary = f"""
**Pre-computed Analysis Summary:**
1. Grouped Averages:
{grouped_analysis_df.to_string()}
2. Overall Averages (for baseline comparison):
{overall_avg_series.to_string()}
3. Coefficient of Variation (Volatility, for metric selection):
{coeff_var_series.to_string()}
"""
                        
                        categorical_summary = ""
                        for col in result_df.select_dtypes(include=['object', 'category']).columns:
                            unique_values = result_df[col].unique()
                            display_values = list(unique_values[:10]) + ['...'] if len(unique_values) > 10 else list(unique_values)
                            categorical_summary += f"- Column '{col}' contains: {display_values}\n"
                        
                        df_info = f"""
**Original Data Info:**
Shape: {result_df.shape}
Columns and Types: {result_df.dtypes.to_dict()}
Categorical Vocabulary: {categorical_summary if categorical_summary else "None"}
"""
                        
                        # è°ƒç”¨LLMè¿›è¡Œæ–‡æœ¬åˆ†æ
                        st.session_state.analysis_report = rag_engine.llm.analyze_telecom_data(
                            df_info=df_info,
                            pre_analysis_summary=pre_analysis_summary, # <--- ç¡®ä¿è¿™ä¸ªå‚æ•°è¢«ä¼ é€’
                            user_question=st.session_state.current_question,
                            query_result_sample=result_df.head(3).to_string()
                        )

                    except Exception as e:
                        st.error(f"æ•°æ®åˆ†æå¤±è´¥: {str(e)}")
                        if debug_mode: st.exception(e)

            # æ˜¾ç¤ºå››ç»´åˆ†ææŠ¥å‘Š
            if st.session_state.analysis_report:
                report = st.session_state.analysis_report
                
                dimension_keys = ["overview_analysis", "time_series_analysis", "geo_distribution_analysis", "anomaly_diagnosis"]
                
                for i, key in enumerate(dimension_keys):
                    if report.get(key):
                        st.divider()
                        insight = report[key]
                        st.markdown(f"#### {insight.get('title', key.replace('_', ' ').title())}")
                        if insight.get('explanation'):
                            st.caption(insight['explanation'])
                        
                        # --- START: æ–°çš„ "æç‚¼-å†æŸ¥è¯¢-å¯è§†åŒ–" é€»è¾‘ ---
                        chart_data_key = f"chart_data_{i}"
                        
                        if st.button(f"ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨", key=f"gen_chart_{i}"):
                            with st.spinner(f"æ­£åœ¨ä¸ºã€{insight.get('title', 'åˆ†æ')}ã€‘æç‚¼æ•°æ®..."):
                                try:
                                    new_question = insight['explanation']
                                    sql_result = rag_engine.generate_sql_only(new_question)
                                    chart_sql = sql_result.get("sql")
                                    
                                    if debug_mode:
                                        with st.expander("æŸ¥çœ‹å›¾è¡¨ç”Ÿæˆçš„SQL"):
                                            st.code(chart_sql, language='sql')

                                    chart_df = rag_engine.db.execute_query(chart_sql)
                                    st.session_state[chart_data_key] = chart_df

                                except Exception as e:
                                    st.error(f"å›¾è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
                                    st.session_state[chart_data_key] = pd.DataFrame() # å‡ºé”™æ—¶ç½®ä¸ºç©ºDF

                        if chart_data_key in st.session_state:
                            chart_df = st.session_state[chart_data_key]
                            if chart_df is not None and not chart_df.empty:
                                chart_obj = build_simple_chart(chart_df, insight.get('title', ''))
                                if chart_obj:
                                    st_pyecharts(chart_obj, height="500px")
                                else:
                                    st.warning("æ— æ³•ä¸ºæ­¤æ•°æ®è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨ã€‚")
                            elif chart_df is not None: # å¦‚æœæ˜¯ç©ºçš„DataFrame
                                st.info("ä¸ºéªŒè¯æ­¤åˆ†æç‚¹æŸ¥è¯¢åˆ°çš„æ•°æ®ä¸ºç©ºã€‚")
                        # --- END: æ–°é€»è¾‘ ---

                st.divider()
                if st.button("ğŸ”„ é‡æ–°åˆ†æ", type="secondary"):
                    st.session_state.analysis_report = None
                    for i in range(len(dimension_keys)):
                        if f"chart_data_{i}" in st.session_state: del st.session_state[f"chart_data_{i}"]
                    st.rerun()



# 2. æ‰¹é‡/å¢é‡è®­ç»ƒç•Œé¢
with tabs[1]:
    st.header("æ‰¹é‡/å¢é‡è®­ç»ƒæ•°æ®ä¸Šä¼ ")
    
    # åˆå§‹åŒ–å˜é‡
    doc_list = []
    qa_pairs = []
    
    # æ–°å¢ï¼šè‡ªåŠ¨å¯¼å…¥æ•°æ®åº“ç»“æ„
    st.subheader("0. è‡ªåŠ¨å¯¼å…¥æ•°æ®åº“ç»“æ„")
    col1, col2 = st.columns([3, 1])
    with col1:
        st.info("ä»å·²è¿æ¥çš„MySQLæ•°æ®åº“è‡ªåŠ¨å¯¼å…¥è¡¨ç»“æ„ä¿¡æ¯")
    with col2:
        if st.button("ğŸ”„ å¯¼å…¥æ•°æ®åº“ç»“æ„", type="secondary"):
            with st.spinner("æ­£åœ¨è¯»å–æ•°æ®åº“ç»“æ„..."):
                try:
                    # è·å–æ•°æ®åº“ç»“æ„
                    schema_info = rag_engine.db.get_schema_info()
                    
                    # å‡†å¤‡è®­ç»ƒæ•°æ®
                    auto_ddl_list = []
                    auto_doc_list = []
                    
                    for table_info in schema_info:
                        # æ·»åŠ DDL
                        auto_ddl_list.append(table_info['ddl'])
                        
                        # æ·»åŠ è¡¨è¯´æ˜æ–‡æ¡£
                        table_doc = f"è¡¨å: {table_info['table_name']}"
                        if table_info['table_comment']:
                            table_doc += f", è¯´æ˜: {table_info['table_comment']}"
                        
                        # æ·»åŠ åˆ—è¯´æ˜
                        col_docs = []
                        for col in table_info['columns']:
                            if col.get('COLUMN_COMMENT'):
                                col_docs.append(f"{col['COLUMN_NAME']}: {col['COLUMN_COMMENT']}")
                        
                        if col_docs:
                            table_doc += ", å­—æ®µè¯´æ˜: " + "; ".join(col_docs)
                        
                        auto_doc_list.append(table_doc)
                        
                        # è·å–æ ·ä¾‹æ•°æ®
                        try:
                            sample_df = rag_engine.db.get_sample_data(table_info['table_name'], limit=3)
                            if not sample_df.empty:
                                sample_doc = f"è¡¨{table_info['table_name']}çš„æ ·ä¾‹æ•°æ®: {sample_df.to_string()}"
                                auto_doc_list.append(sample_doc)
                        except:
                            pass
                    
                    # æ‰§è¡Œè®­ç»ƒ
                    counts = trainer.train_incremental(auto_ddl_list, auto_doc_list, [])
                    
                    st.success(f"âœ… æˆåŠŸå¯¼å…¥ {len(schema_info)} ä¸ªè¡¨çš„ç»“æ„ä¿¡æ¯ï¼")
                    
                    # æ˜¾ç¤ºå¯¼å…¥çš„è¡¨
                    with st.expander("æŸ¥çœ‹å¯¼å…¥çš„è¡¨"):
                        for table_info in schema_info:
                            st.write(f"- {table_info['table_name']}: {table_info.get('table_comment', '')}")
                    
                except Exception as e:
                    st.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
    
    st.divider()

    # æ–‡æ¡£è¾“å…¥
    st.subheader("1. å¯¼å…¥ä¸šåŠ¡æ–‡æ¡£")
    doc_input = st.text_area("æ¯è¡Œä¸€æ®µä¸šåŠ¡æ–‡æ¡£å†…å®¹", height=150, key="doc_input")
    if doc_input:
        doc_list = [x.strip() for x in doc_input.split('\n') if x.strip()]
        if doc_list:
            st.info(f"å·²è¾“å…¥ {len(doc_list)} æ¡æ–‡æ¡£")

    # é—®ç­”å¯¹æ–‡ä»¶ä¸Šä¼ 
    st.subheader("2. å¯¼å…¥SQLé—®ç­”å¯¹")
    
    # æä¾›ç¤ºä¾‹æ ¼å¼
    with st.expander("æŸ¥çœ‹æ–‡ä»¶æ ¼å¼è¦æ±‚"):
        st.write("CSVæˆ–Excelæ–‡ä»¶éœ€è¦åŒ…å«ä»¥ä¸‹ä¸¤åˆ—ï¼š")
        example_df = pd.DataFrame({
            "question": ["æ¹–åŒ—çœç½‘ç»œçš„åŸºç«™æ•°é‡å’Œå°åŒºæ•°é‡", "æŸ¥è¯¢å„åœ°å¸‚çš„åŸºç«™æ•°é‡"],
            "sql": [
                "SELECT `çœä»½`,COUNT(DISTINCT station_name) AS `åŸºç«™æ•°é‡`, COUNT(DISTINCT cell_name) AS `å°åŒºæ•°é‡` FROM btsbase WHERE `çœä»½` = 'æ¹–åŒ—çœ' GROUP BY `çœä»½`;",
                "SELECT `åœ°å¸‚`, COUNT(DISTINCT station_name) AS `åŸºç«™æ•°é‡` FROM btsbase GROUP BY `åœ°å¸‚`;"
            ]
        })
        st.dataframe(example_df)
    
    qa_file = st.file_uploader("ä¸Šä¼ é—®ç­”å¯¹æ–‡ä»¶ï¼ˆcsv/xlsxï¼‰", type=["csv", "xlsx"])
    
    if qa_file:
        try:
            if qa_file.name.endswith(".csv"):
                df_qa = pd.read_csv(qa_file)
            else:
                df_qa = pd.read_excel(qa_file)
                
            if "question" not in df_qa.columns or "sql" not in df_qa.columns:
                st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å« 'question' å’Œ 'sql' ä¸¤åˆ—")
                qa_pairs = []
            else:
                qa_pairs = df_qa[["question", "sql"]].dropna().to_dict("records")
                st.success(f"âœ… å·²è¯»å– {len(qa_pairs)} æ¡é—®ç­”å¯¹")
                
                # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®é¢„è§ˆ
                if st.checkbox("é¢„è§ˆæ•°æ®"):
                    st.dataframe(df_qa.head())
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
            qa_pairs = []

    # è®­ç»ƒé€‰é¡¹
    st.divider()
    incremental = st.checkbox("ä»…å¢é‡è®­ç»ƒï¼ˆè·³è¿‡å·²å…¥åº“å†…å®¹ï¼‰", value=True)
    
    # æ˜¾ç¤ºå¾…è®­ç»ƒæ•°æ®ç»Ÿè®¡
    total_items = len(doc_list) + len(qa_pairs)
    if total_items > 0:
        st.info(f"ğŸ“Š å¾…è®­ç»ƒæ•°æ®ç»Ÿè®¡ï¼šæ–‡æ¡£ {len(doc_list)}æ¡ï¼Œé—®ç­”å¯¹ {len(qa_pairs)}æ¡")
    
    # å¼€å§‹è®­ç»ƒæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒ", type="primary", disabled=(total_items == 0)):
        with st.spinner("è®­ç»ƒä¸­ï¼Œè¯·ç¨å€™..."):
            try:
                # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ç©ºçš„DDLåˆ—è¡¨
                if incremental:
                    counts = trainer.train_incremental([], doc_list, qa_pairs)
                    st.success(f"âœ… å¢é‡è®­ç»ƒå®Œæˆï¼æ–°å¢ï¼šæ–‡æ¡£ {counts['doc']}æ¡ï¼Œé—®ç­”å¯¹ {counts['qa']}æ¡")
                else:
                    counts = trainer.train_all([], doc_list, qa_pairs)
                    st.success(f"âœ… æ‰¹é‡è®­ç»ƒå®Œæˆï¼æˆåŠŸï¼šæ–‡æ¡£ {counts['doc']}æ¡ï¼Œé—®ç­”å¯¹ {counts['qa']}æ¡")
                
                # æ˜¾ç¤ºå‘é‡åº“çŠ¶æ€
                try:
                    db_info = trainer.vector_db.get_collection_info()
                    st.info(f"ğŸ“š å‘é‡åº“å½“å‰æ–‡æ¡£æ€»æ•°: {db_info.get('count', 'N/A')}")
                except:
                    pass
                
            except Exception as e:
                st.error(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
                st.exception(e)
    
    # æ¸…ç©ºæŒ‰é’®
    if total_items > 0:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºè¾“å…¥"):
            st.rerun()


# ä¾§è¾¹æ ä¿¡æ¯ï¼ˆä¿æŒä¸å˜ï¼‰
with st.sidebar:
    st.title("ç³»ç»Ÿä¿¡æ¯")
    st.write("NL2SQL RAG Demo")
    st.write("åŸºäº Claude + ChromaDB + MySQL")
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    st.divider()
    st.subheader("ç³»ç»ŸçŠ¶æ€")
    try:
        db_info = trainer.vector_db.get_collection_info()
        st.metric("å‘é‡åº“æ–‡æ¡£æ•°", db_info.get('count', 0))
    except:
        st.metric("å‘é‡åº“æ–‡æ¡£æ•°", "æœªè¿æ¥")
    
    # æ·»åŠ æµ‹è¯•æ•°æ®æŒ‰é’®
    st.divider()
    if st.button("æ·»åŠ æµ‹è¯•æ•°æ®"):
        test_ddl = [
            "CREATE TABLE btsbase (ID INT PRIMARY KEY, station_name VARCHAR(100), cell_name VARCHAR(100), `çœä»½` VARCHAR(50), `åœ°å¸‚` VARCHAR(50), frequency_band VARCHAR(20))",
            "CREATE TABLE kpibase (ID INT PRIMARY KEY, `å¼€å§‹æ—¶é—´` DATETIME, R1001_012 BIGINT, R1001_001 BIGINT, R1034_012 BIGINT, R1034_001 BIGINT, R1039_002 BIGINT, R1039_001 BIGINT, R2032_012 BIGINT, R2032_001 BIGINT, R1012_001 BIGINT, R1012_002 BIGINT, K1009_001 BIGINT, K1009_002 BIGINT, R1004_002 BIGINT, R1004_003 BIGINT, R1004_004 BIGINT, R1004_007 BIGINT, R1005_012 BIGINT, R1006_012 BIGINT)"
        ]
        test_docs = [
            "btsbaseè¡¨åŒ…å«5GåŸºç«™çš„åŸºç¡€ä¿¡æ¯ï¼ŒåŒ…æ‹¬åŸºç«™åç§°ã€å°åŒºåç§°ã€çœä»½ã€åœ°å¸‚ã€é¢‘æ®µç­‰",
            "kpibaseè¡¨åŒ…å«5Gç½‘ç»œçš„KPIæŒ‡æ ‡æ•°æ®ï¼ŒåŒ…æ‹¬å„ç§æ€§èƒ½è®¡æ•°å™¨çš„å€¼",
            "æ— çº¿æ¥é€šç‡è®¡ç®—å…¬å¼ï¼š100 * (R1001_012/R1001_001) * (R1034_012/R1034_001) * (R1039_002/R1039_001)",
            "æ— çº¿æ‰çº¿ç‡è®¡ç®—å…¬å¼ï¼š100 * (R1004_003 - R1004_004) / (R1004_002 + R1004_007 + R1005_012 + R1006_012)",
            "åŸºç«™æ•°é‡é€šè¿‡COUNT(DISTINCT station_name)ç»Ÿè®¡ï¼Œå°åŒºæ•°é‡é€šè¿‡COUNT(DISTINCT cell_name)ç»Ÿè®¡"
        ]
        test_qa = [
            {
                "question": "æŸ¥è¯¢æ¹–åŒ—çœçš„åŸºç«™æ•°é‡",
                "sql": "SELECT 'æ¹–åŒ—çœ' AS `çœä»½`, COUNT(DISTINCT station_name) AS `åŸºç«™æ•°é‡` FROM btsbase WHERE `çœä»½` = 'æ¹–åŒ—çœ'"
            },
            {
                "question": "ç»Ÿè®¡å„åœ°å¸‚çš„åŸºç«™æ•°é‡",
                "sql": "SELECT `åœ°å¸‚`, COUNT(DISTINCT station_name) AS `åŸºç«™æ•°é‡` FROM btsbase GROUP BY `åœ°å¸‚` ORDER BY `åŸºç«™æ•°é‡` DESC"
            },
            {
                "question": "æŸ¥è¯¢æ¹–åŒ—çœçš„æ•°æ®ä¸šåŠ¡çš„ç½‘ç»œæ€§èƒ½æŒ‡æ ‡",
                "sql": "select b.`çœä»½`, k.`å¼€å§‹æ—¶é—´`, round(100 * (SUM(k.R1001_012) / nullif(SUM(k.R1001_001), 0)) * (SUM(k.R1034_012) / nullif(SUM(k.R1034_001), 0)) * (SUM(k.R1039_002) / nullif(SUM(k.R1039_001), 0)), 2) as æ— çº¿æ¥é€šç‡, round(100 * (SUM(k.R1004_003) - SUM(k.R1004_004)) / nullif(SUM(k.R1004_002) + SUM(k.R1004_007) + SUM(k.R1005_012) + SUM(k.R1006_012), 0), 2) as æ— çº¿æ‰çº¿ç‡, round(100 * SUM(k.R2007_002 + k.R2007_004 + k.R2006_004 + k.R2006_008 + k.R2005_004 + k.R2005_008) / nullif(SUM(k.R2007_001 + k.R2007_003 + k.R2006_001 + k.R2006_005 + k.R2005_001 + k.R2005_005), 0), 2) as ç³»ç»Ÿå†…åˆ‡æ¢æˆåŠŸç‡, round(100 * SUM(k.R2075_001 + k.R2040_014) / nullif(SUM(k.R2034_033), 0), 2) as EPSFallbackVoLTEå›è½æˆåŠŸç‡ from btsbase b inner join kpibase k on b.ID = k.ID group by b.`çœä»½`, k.`å¼€å§‹æ—¶é—´` order by k.`å¼€å§‹æ—¶é—´`;"
            },
            {
                "question": "æŸ¥è¯¢æ¹–åŒ—çœæ•°æ®ä¸šåŠ¡æµé‡æŒ‡æ ‡",
                "sql": "select b.`çœä»½`, k.`å¼€å§‹æ—¶é—´`, round((SUM(k.R1012_001) + SUM(k.R1012_002)),2) / 1e6 AS æ•°æ®ä¸šåŠ¡æµé‡, round(SUM(k.R2032_012) / 1e6,2) AS ä¸‹è¡Œæ•°æ®ä¸šåŠ¡æµé‡, round(SUM(k.R2032_001) / 1e6,2) AS ä¸Šè¡Œæ•°æ®ä¸šåŠ¡æµé‡ FROM btsbase b INNER JOIN kpibase k ON b.ID = k.ID GROUP BY b.`çœä»½`, k.`å¼€å§‹æ—¶é—´` order by k.`å¼€å§‹æ—¶é—´`;"
            },
            {
                "question": "æŸ¥è¯¢æ¹–åŒ—çœçš„VONRçš„ç½‘ç»œæ€§èƒ½æŒ‡æ ‡",
                "sql": "select b.`çœä»½`, k.`å¼€å§‹æ—¶é—´`, round(100 * (SUM(k.R1034_013) / NULLIF(SUM(k.R1034_002), 0)) * SUM(k.R1001_018 + k.R1001_015) / NULLIF(SUM(k.R1001_007 + k.R1001_004), 0), 2) AS VoNRæ— çº¿æ¥é€šç‡, round(100 * SUM(k.R2035_003 - k.R2035_013) / NULLIF(SUM(k.R2035_003 + k.R2035_026), 0), 2) AS VoNRè¯­éŸ³æ‰çº¿ç‡, round(100 * SUM(k.R2005_063 + k.R2005_067 + k.R2006_071 + k.R2006_075 + k.R2007_036 + k.R2007_040) / NULLIF(SUM(k.R2005_060 + k.R2005_064 + k.R2006_068 + k.R2006_072 + k.R2007_033 + k.R2007_037), 0), 2) AS VoNRç³»ç»Ÿå†…åˆ‡æ¢æˆåŠŸç‡ FROM btsbase b INNER JOIN kpibase k ON b.ID = k.ID GROUP BY b.`çœä»½`, k.`å¼€å§‹æ—¶é—´` order by k.`å¼€å§‹æ—¶é—´`;"
            }
        ]
        
        with st.spinner("æ·»åŠ æµ‹è¯•æ•°æ®..."):
            try:
                counts = trainer.train_all(test_ddl, test_docs, test_qa)
                st.success("æµ‹è¯•æ•°æ®æ·»åŠ å®Œæˆï¼")
            except Exception as e:
                st.error(f"æ·»åŠ æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}")
    
    # æ·»åŠ é€šä¿¡è¡Œä¸šå¸¸è§æŸ¥è¯¢
    if st.button("æŸ¥çœ‹é€šä¿¡è¡Œä¸šç¤ºä¾‹"):
        with st.expander("ç¤ºä¾‹æŸ¥è¯¢", expanded=True):
            st.write("**Q: æŸ¥è¯¢æ¹–åŒ—çœçš„æ— çº¿æ¥é€šç‡è¶‹åŠ¿**")
            st.code("""SELECT b.`çœä»½`, k.`å¼€å§‹æ—¶é—´`, 
    ROUND(100 * (SUM(k.R1001_012) / NULLIF(SUM(k.R1001_001), 0)) * 
    (SUM(k.R1034_012) / NULLIF(SUM(k.R1034_001), 0)) * 
    (SUM(k.R1039_002) / NULLIF(SUM(k.R1039_001), 0)), 2) AS `æ— çº¿æ¥é€šç‡`
FROM btsbase b 
INNER JOIN kpibase k ON b.ID = k.ID 
WHERE b.`çœä»½` = 'æ¹–åŒ—çœ' 
GROUP BY b.`çœä»½`, k.`å¼€å§‹æ—¶é—´` 
ORDER BY k.`å¼€å§‹æ—¶é—´`""", language='sql')
            
            st.write("**Q: ç»Ÿè®¡å„åœ°å¸‚çš„åŸºç«™æ•°é‡**")
            st.code("SELECT `åœ°å¸‚`, COUNT(DISTINCT station_name) AS `åŸºç«™æ•°é‡` FROM btsbase GROUP BY `åœ°å¸‚` ORDER BY `åŸºç«™æ•°é‡` DESC", language='sql')
            
            st.write("**Q: æŸ¥è¯¢æ•°æ®ä¸šåŠ¡æµé‡æŒ‡æ ‡**")
            st.code("""SELECT b.`çœä»½`, 
    ROUND(SUM(k.R2032_012) / 1e6, 2) as `æ•°æ®ä¸šåŠ¡ä¸‹è¡Œæµé‡`, 
    ROUND(SUM(k.R2032_001) / 1e6, 2) as `æ•°æ®ä¸šåŠ¡ä¸Šè¡Œæµé‡`,
    ROUND((SUM(k.R1012_001) + SUM(k.R1012_002)) / 1024 / 1024, 2) as `æ•°æ®ä¸šåŠ¡æµé‡`
FROM btsbase b 
INNER JOIN kpibase k ON b.ID = k.ID 
GROUP BY b.`çœä»½`
ORDER BY `æ•°æ®ä¸šåŠ¡æµé‡` DESC""", language='sql')
    
    # æ¸…ç©ºå‘é‡åº“åŠŸèƒ½
    st.divider()
    st.subheader("æ•°æ®åº“ç®¡ç†")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå‘é‡åº“", type="secondary"):
        confirm = st.checkbox("ç¡®è®¤æ¸…ç©ºæ‰€æœ‰è®­ç»ƒæ•°æ®", key="confirm_clear")
        if confirm:
            try:
                # æ¸…ç©ºå‘é‡æ•°æ®åº“
                trainer.vector_db.clear_all()
                st.success("å‘é‡åº“å·²æ¸…ç©ºï¼")
                st.rerun()
            except Exception as e:
                st.error(f"æ¸…ç©ºå¤±è´¥: {str(e)}")
        else:
            st.warning("è¯·å‹¾é€‰ç¡®è®¤æ¡†ä»¥æ¸…ç©ºå‘é‡åº“")











